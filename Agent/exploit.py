"""
Exploit Agent - Generates pwntools exploit code.

Responsibilities:
- Generate working pwntools exploit code
- Use all gathered analysis information
- Handle edge cases and protections
"""

import time
from pathlib import Path
from typing import Any, Dict, List, Optional

from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax

from Agent.base import BaseAgent, parse_json_response, is_response_truncated
from Templates.prompt import (
    build_messages, build_stage_exploit_messages, build_analysis_document,
    STAGE_IDENTIFY_SYSTEM, STAGE_IDENTIFY_USER,
    STAGE_REFINE_SYSTEM, STAGE_REFINE_USER,
)
from Store.knowledge import get_checksec_guide, get_heap_techniques, get_technique_guide, get_heap_constraint_guide

console = Console()


class ExploitAgent(BaseAgent):
    """
    Exploit Agent for PWN Solver.
    
    - Generate pwntools exploit code
    - Use all gathered analysis information
    """
    
    def __init__(
        self,
        model: Optional[str] = None,
        provider: Optional[str] = None,
        **kwargs
    ):
        super().__init__(name="ExploitAgent", model=model, provider=provider, **kwargs)
    
    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Run Exploit Agent."""
        console.print(Panel("Exploit Agent", style="bold red"))

        self.clear_history()

        # Build messages with full analysis
        messages = build_messages(
            agent="exploit",
            state=state,
            include_initial=False,
        )

        # Set system prompt and add user message
        if messages:
            self.set_system_prompt(messages[0]["content"])
            for msg in messages[1:]:
                if msg["role"] == "user":
                    self.add_user_message(msg["content"])

        # Inject Knowledge Base techniques into context
        kb_context = self._build_kb_context(state)
        if kb_context:
            self.add_user_message(kb_context)
        
        console.print("[cyan]Calling LLM for exploit generation...[/cyan]")
        response_text = self.call_llm()
        
        # Parse response
        parsed = parse_json_response(response_text)

        state["exploit_output"] = {
            "agent": "exploit",
            "text": response_text,
            "json": parsed,
            "created_at": time.time(),
        }

        # Extract and display exploit code
        exploit_code = parsed.get("exploit_code", "")
        exploit_type = parsed.get("exploit_type", "unknown")

        # Fallback: Try to extract code from raw response if JSON parsing failed
        if not exploit_code and ("from pwn import" in response_text or "from pwnlib" in response_text):
            exploit_code = self._extract_code_from_raw(response_text)
            if exploit_code:
                console.print("[yellow]Extracted exploit code from raw response (JSON parse failed)[/yellow]")
        
        if exploit_code:
            console.print(f"[green]Exploit Type: {exploit_type}[/green]")
            console.print(Panel(
                Syntax(exploit_code, "python", theme="monokai", line_numbers=True),
                title="Generated Exploit",
                border_style="red"
            ))

            # Save exploit to Challenge directory
            exploit_path = self._save_exploit(state, exploit_code)
            if exploit_path:
                state["exploit_path"] = str(exploit_path)
        
        # Show key steps
        key_steps = parsed.get("key_steps", [])
        if key_steps:
            console.print("[cyan]Key Steps:[/cyan]")
            for step in key_steps:
                console.print(f"  {step}")
        
        # Show assumptions
        assumptions = parsed.get("assumptions", [])
        if assumptions:
            console.print("[yellow]Assumptions:[/yellow]")
            for assumption in assumptions:
                console.print(f"  • {assumption}")
        
        return state
    
    def _build_kb_context(self, state: dict) -> str:
        """Build Knowledge Base context for exploit generation."""
        analysis = state.get("analysis", {})
        checksec = analysis.get("checksec", {})
        vulns = analysis.get("vulnerabilities", [])
        libc = analysis.get("libc", {})
        sections = []

        # 1. Checksec-based strategy recommendation
        if checksec.get("done"):
            guide = get_checksec_guide(checksec)
            if guide.get("recommended"):
                sections.append("## Recommended Exploitation Techniques (from Knowledge Base)")
                for tech in guide["recommended"]:
                    sections.append(f"\n### {tech.get('name', '')}")
                    sections.append(f"**Strategy:** {tech.get('strategy', '')}")
                    if tech.get("steps"):
                        sections.append("**Steps:**")
                        for step in tech["steps"]:
                            sections.append(f"  {step}")
                    if tech.get("modern_template"):
                        sections.append(f"**Code Template:**\n```python\n{tech['modern_template'].strip()}\n```")

        # 2. Heap technique templates if heap vuln detected
        vuln_types = [v.get("type", "").lower() for v in vulns]
        is_heap = any(t in ("use_after_free", "heap_overflow", "double_free", "heap", "uaf") for t in vuln_types)
        if is_heap:
            glibc_ver = libc.get("version", "2.35")
            heap_techs = get_heap_techniques(str(glibc_ver))
            if heap_techs:
                sections.append("\n## Applicable Heap Techniques (glibc version-specific)")
                for tech in heap_techs:
                    sections.append(f"\n### {tech.get('name', '')} ({tech.get('key', '')})")
                    sections.append(f"  {tech.get('description', '')}")
                    if tech.get("version_notes"):
                        sections.append(f"  **Version Note:** {tech['version_notes']}")
                    if tech.get("modern_template"):
                        sections.append(f"  **Template:**\n```python\n{tech['modern_template'].strip()}\n```")
                    if tech.get("steps"):
                        sections.append("  **Steps:**")
                        for step in tech["steps"]:
                            sections.append(f"    {step}")

        # 3. Heap constraint guide (pointer structure → leak/write strategy)
        if is_heap:
            pointer_type = analysis.get("heap_pointer_type", "unknown")
            has_uaf = any(t in ("use_after_free", "uaf") for t in vuln_types)
            has_print = bool(analysis.get("io_patterns"))  # has print/read feature
            pie = checksec.get("pie", False)
            glibc_ver_str = str(libc.get("version", "2.35"))

            constraint_guide = get_heap_constraint_guide(
                pointer_type=pointer_type,
                has_uaf=has_uaf,
                has_print=has_print,
                pie=pie,
                glibc_version=glibc_ver_str,
            )

            sections.append("\n## Heap Exploit Strategy (Constraint-based)")
            sections.append(f"**Pointer type:** {constraint_guide['pointer_type']}")
            sections.append(f"**Recommended leak:** {constraint_guide['recommended_leak']}")
            sections.append(f"**Recommended write target:** {constraint_guide['recommended_write_target']}")
            if constraint_guide.get("warnings"):
                sections.append("**WARNINGS:**")
                for w in constraint_guide["warnings"]:
                    sections.append(f"  ⚠ {w}")
            if constraint_guide.get("recommended_flow"):
                sections.append("**Recommended exploit flow:**")
                for step in constraint_guide["recommended_flow"]:
                    sections.append(f"  → {step}")

        # 4. Strategy-specific technique guide
        strategy = analysis.get("strategy", "")
        if strategy:
            tech_guide = get_technique_guide(strategy)
            if tech_guide and tech_guide.get("modern_template"):
                sections.append(f"\n## Strategy-Specific Template: {tech_guide.get('name', strategy)}")
                sections.append(f"```python\n{tech_guide['modern_template'].strip()}\n```")

        return "\n".join(sections) if sections else ""

    def _extract_code_from_raw(self, text: str) -> str:
        """
        Extract Python exploit code from raw LLM response when JSON parsing fails.

        Looks for code blocks or 'from pwn import' patterns.
        """
        import re

        # Try to find code in ```python``` block
        python_match = re.search(r'```python\s*(.*?)```', text, re.DOTALL)
        if python_match:
            code = python_match.group(1).strip()
            if 'from pwn import' in code or 'from pwnlib' in code:
                return code

        # Try to find code in generic ``` block
        code_match = re.search(r'```\s*(from pwn.*?)```', text, re.DOTALL)
        if code_match:
            return code_match.group(1).strip()

        # Try to extract from "exploit_code": "..." in malformed JSON
        # Handle escaped newlines
        code_match = re.search(r'"exploit_code"\s*:\s*"((?:[^"\\]|\\.)*)', text, re.DOTALL)
        if code_match:
            code = code_match.group(1)
            # Unescape
            code = code.replace('\\n', '\n').replace('\\t', '\t').replace('\\"', '"').replace('\\\\', '\\')
            if 'from pwn import' in code or 'from pwnlib' in code:
                return code

        # Last resort: find 'from pwn import' and take everything until end or next section
        pwn_match = re.search(r'(from pwn import \*.*?)(?:```|\n\n\n|"reasoning"|$)', text, re.DOTALL)
        if pwn_match:
            return pwn_match.group(1).strip()

        return ""

    def _save_exploit(self, state: Dict[str, Any], exploit_code: str) -> Optional[Path]:
        """Save exploit to Challenge directory."""
        binary_path = state.get("binary_path", "")
        if not binary_path:
            return None
        
        # Save to same directory as the binary
        binary_dir = Path(binary_path).resolve().parent
        exploit_path = binary_dir / "exploit.py"
        exploit_path.write_text(exploit_code, encoding="utf-8")
        
        console.print(f"[green]Exploit saved to: {exploit_path}[/green]")
        return exploit_path


# =============================================================================
# Exploit Refinement (for iterative improvement)
# =============================================================================

class ExploitRefinerAgent(BaseAgent):
    """
    Exploit Refiner Agent - Fixes failed exploits based on error output.
    
    This agent is used when the initial exploit fails verification.
    It analyzes the error and modifies the exploit code.
    """
    
    def __init__(
        self,
        model: Optional[str] = None,
        provider: Optional[str] = None,
        **kwargs
    ):
        super().__init__(name="ExploitRefinerAgent", model=model, provider=provider, **kwargs)
    
    def run(
        self,
        state: Dict[str, Any],
        error_output: str,
        current_exploit: str,
    ) -> Dict[str, Any]:
        """
        Refine exploit based on error.
        
        Args:
            state: Current solver state
            error_output: Error message from failed execution
            current_exploit: Current exploit code that failed
        """
        console.print(Panel("Exploit Refiner", style="bold orange1"))
        
        # Build refinement prompt
        system_prompt = """You are an expert at debugging pwntools exploits.

Given a failed exploit and its error output, fix the code to work correctly.

Output Format (STRICT JSON):
```json
{
  "reasoning": "Analysis of what went wrong and how to fix it",
  "exploit_code": "from pwn import *\\n\\n# Fixed exploit code...",
  "changes_made": ["List of changes made to fix the exploit"]
}
```

Focus on:
- Stack alignment issues (ret gadget)
- Incorrect offsets
- Wrong addresses
- Missing null byte handling
- Timing issues

CRITICAL: NEVER use p.interactive(). After triggering shell, verify it:
```python
import time
time.sleep(0.5)
p.sendline(b'id')
time.sleep(0.5)
response = p.recvrepeat(timeout=2)
if b'uid=' in response:
    print('SHELL_VERIFIED')
    print(response.decode(errors='ignore'))
else:
    print('SHELL_FAILED')
    print(response.decode(errors='ignore'))
p.close()
```
"""
        
        # Build failure history context
        failure_history = state.get("exploit_failure_history", [])
        history_text = ""
        if len(failure_history) > 1:  # More than just the current failure
            history_text = "\n## Previous Failed Attempts (DO NOT REPEAT)\n"
            for f in failure_history[:-1]:  # Exclude current (already shown above)
                history_text += f"\n### Attempt {f.get('attempt', '?')}\n"
                history_text += f"Error: {f.get('error_summary', '')[:300]}\n"

        user_prompt = f"""## Current Exploit (FAILED)

```python
{current_exploit}
```

## Error Output

```
{error_output}
```

## Analysis Document

Binary: {state.get("binary_path", "")}
Protections: {state.get("analysis", {}).get("checksec", {}).get("result", "Unknown")}
{history_text}
Please analyze the error and provide a fixed exploit.
"""
        
        self.set_system_prompt(system_prompt)
        self.add_user_message(user_prompt)
        
        console.print("[cyan]Calling LLM for exploit refinement...[/cyan]")
        response_text = self.call_llm()
        
        # Parse response
        parsed = parse_json_response(response_text)

        # Get fixed exploit
        fixed_exploit = parsed.get("exploit_code", "")

        # Fallback: Try to extract code from raw response if JSON parsing failed
        if not fixed_exploit and ("from pwn import" in response_text or "from pwnlib" in response_text):
            fixed_exploit = ExploitAgent()._extract_code_from_raw(response_text)
            if fixed_exploit:
                console.print("[yellow]Extracted exploit code from raw response (JSON parse failed)[/yellow]")

        if fixed_exploit:
            console.print("[green]Exploit refined[/green]")
            
            if "changes_made" in parsed:
                console.print("[cyan]Changes Made:[/cyan]")
                for change in parsed["changes_made"]:
                    console.print(f"  • {change}")
            
            # Update state with new exploit
            state["exploit_output"] = {
                "agent": "exploit_refiner",
                "text": response_text,
                "json": parsed,
                "created_at": time.time(),
            }
            
            # Save refined exploit
            ExploitAgent()._save_exploit(state, fixed_exploit)

        return state


# =============================================================================
# Staged Exploit Agents (단계별 익스플로잇)
# =============================================================================

class StageIdentifierAgent(BaseAgent):
    """
    단계 식별 Agent - 분석 결과 기반으로 exploit 단계를 결정.

    출력: stages 리스트 [{stage_id, description, verification_marker}, ...]
    """

    def __init__(self, model=None, provider=None, **kwargs):
        super().__init__(name="StageIdentifierAgent", model=model, provider=provider, **kwargs)

    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Identify exploit stages from analysis."""
        console.print(Panel("Stage Identifier", style="bold magenta"))
        self.clear_history()

        analysis = state.get("analysis", {})

        # Build messages
        system_content = STAGE_IDENTIFY_SYSTEM.render()
        user_content = STAGE_IDENTIFY_USER.render(
            analysis_document=build_analysis_document(state),
            binary_path=state.get("binary_path", ""),
        )

        self.set_system_prompt(system_content)
        self.add_user_message(user_content)

        # Inject KB constraint guide (heap pointer type, leak strategy, etc.)
        kb_context = ExploitAgent()._build_kb_context(state)
        if kb_context:
            self.add_user_message(kb_context)

        # Inject deterministic stage hints
        kb_hint = self._build_stage_hint(analysis)
        if kb_hint:
            self.add_user_message(kb_hint)

        console.print("[cyan]Calling LLM for stage identification...[/cyan]")
        response_text = self.call_llm()
        parsed = parse_json_response(response_text)

        stages_raw = parsed.get("stages", [])
        if not stages_raw:
            # Fallback: single trigger stage
            console.print("[yellow]No stages identified, defaulting to single trigger stage[/yellow]")
            stages_raw = [{"stage_id": "trigger", "description": "Full exploit", "verification_marker": "SHELL_VERIFIED"}]

        # Build ExploitStage list
        stages = []
        for i, s in enumerate(stages_raw):
            stages.append({
                "stage_id": s.get("stage_id", f"stage{i+1}"),
                "stage_index": i,
                "description": s.get("description", ""),
                "code": "",
                "verified": False,
                "verification_marker": s.get("verification_marker", f"STAGE{i+1}_OK"),
                "output": "",
                "error": "",
                "refinement_attempts": 0,
            })

        # Ensure last stage marker is SHELL_VERIFIED
        if stages:
            stages[-1]["verification_marker"] = "SHELL_VERIFIED"

        state["staged_exploit"] = {
            "stages": stages,
            "current_stage_index": 0,
            "all_stages_verified": False,
        }

        # Display
        console.print(f"[green]Identified {len(stages)} stages:[/green]")
        for s in stages:
            console.print(f"  {s['stage_index']+1}. [{s['stage_id']}] {s['description']} → {s['verification_marker']}")

        if parsed.get("reasoning"):
            console.print(Panel(parsed["reasoning"], title="Reasoning", border_style="dim"))

        return state

    def _build_stage_hint(self, analysis: dict) -> str:
        """Build deterministic hints for stage identification."""
        checksec = analysis.get("checksec", {})
        vulns = analysis.get("vulnerabilities", [])
        result_str = str(checksec.get("result", "")).lower()

        hints = []

        # Protection hints
        nx = "nx enabled" in result_str
        pie = "pie" in result_str and "no pie" not in result_str
        canary = "canary found" in result_str and "no canary" not in result_str

        vuln_types = [v.get("type", "").lower() for v in vulns]
        is_heap = any(t in ("use_after_free", "heap_overflow", "double_free", "uaf") for t in vuln_types)
        is_fmt = any(t in ("format_string",) for t in vuln_types)

        if canary:
            hints.append("HINT: Canary detected → likely need a canary leak stage before overflow.")

        if nx and not is_heap and not is_fmt:
            hints.append("HINT: NX enabled, likely ret2libc → stages: leak (GOT leak) → trigger (system/one_gadget).")

        if is_heap:
            pointer_type = analysis.get("heap_pointer_type", "unknown")
            hints.append(f"HINT: Heap vulnerability detected (pointer type: {pointer_type}). "
                        "Likely stages: leak → write → trigger.")
            if pointer_type == "single":
                hints.append(
                    "CRITICAL: Single pointer program — unsorted bin leak WILL NOT WORK.\n"
                    "  - Only one chunk tracked at a time → no guard chunk → freed chunk merges with top.\n"
                    "  - You MUST use stdout BSS partial overwrite technique for the leak stage.\n"
                    "  - Stage description must mention 'stdout BSS partial overwrite', NOT 'unsorted bin'."
                )
            elif pointer_type == "array":
                hints.append(
                    "HINT: Array pointer program — unsorted bin leak works (can keep guard chunk)."
                )

        if is_fmt:
            hints.append("HINT: Format string detected → stages: leak (%p) → write (%n GOT overwrite) → trigger.")

        return "\n".join(hints) if hints else ""


class StageExploitAgent(BaseAgent):
    """
    단계별 Exploit 코드 생성 Agent.

    현재 단계에 대한 완전한 실행 가능 스크립트를 생성.
    이전 verified 단계의 코드를 포함.
    """

    def __init__(self, model=None, provider=None, **kwargs):
        super().__init__(name="StageExploitAgent", model=model, provider=provider, **kwargs)

    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Generate exploit code for current stage."""
        staged = state.get("staged_exploit", {})
        stages = staged.get("stages", [])
        current_idx = staged.get("current_stage_index", 0)

        if current_idx >= len(stages):
            console.print("[red]No more stages to generate[/red]")
            return state

        current_stage = stages[current_idx]
        console.print(Panel(
            f"Stage {current_idx+1}/{len(stages)}: {current_stage['stage_id']} — {current_stage['description']}",
            style="bold red"
        ))
        self.clear_history()

        # Collect verified stages' code
        verified_stages = []
        for s in stages[:current_idx]:
            if s.get("verified") and s.get("code"):
                verified_stages.append({
                    "stage_id": s["stage_id"],
                    "code": s["code"],
                    "output": s.get("output", "")[:500],
                })

        # Build messages
        messages = build_stage_exploit_messages(state, current_stage, verified_stages)

        self.set_system_prompt(messages[0]["content"])
        for msg in messages[1:]:
            if msg["role"] == "user":
                self.add_user_message(msg["content"])

        # Inject KB context
        kb_context = ExploitAgent()._build_kb_context(state)
        if kb_context:
            self.add_user_message(kb_context)

        console.print(f"[cyan]Calling LLM for Stage {current_idx+1} code generation...[/cyan]")
        response_text = self.call_llm()
        parsed = parse_json_response(response_text)

        exploit_code = parsed.get("exploit_code", "")
        if not exploit_code and ("from pwn import" in response_text or "from pwnlib" in response_text):
            exploit_code = ExploitAgent()._extract_code_from_raw(response_text)
            if exploit_code:
                console.print("[yellow]Extracted code from raw response[/yellow]")

        if exploit_code:
            current_stage["code"] = exploit_code

            console.print(Panel(
                Syntax(exploit_code, "python", theme="monokai", line_numbers=True),
                title=f"Stage {current_idx+1}: {current_stage['stage_id']}",
                border_style="red"
            ))

            # Save to file
            exploit_path = self._save_stage_exploit(state, exploit_code)
            if exploit_path:
                state["exploit_path"] = str(exploit_path)

            # Show key steps
            for step in parsed.get("key_steps", []):
                console.print(f"  {step}")
        else:
            console.print("[red]Failed to generate exploit code for this stage[/red]")

        stages[current_idx] = current_stage
        state["staged_exploit"]["stages"] = stages

        return state

    def _save_stage_exploit(self, state: Dict[str, Any], code: str) -> Optional[Path]:
        """Save stage exploit to Challenge directory."""
        binary_path = state.get("binary_path", "")
        if not binary_path:
            return None

        binary_dir = Path(binary_path).resolve().parent
        exploit_path = binary_dir / "exploit.py"
        exploit_path.write_text(code, encoding="utf-8")
        console.print(f"[green]Stage exploit saved to: {exploit_path}[/green]")
        return exploit_path


class StageRefinerAgent(BaseAgent):
    """
    단계별 Exploit 수정 Agent.

    실패한 단계의 코드만 수정. 이전 verified 단계는 건드리지 않음.
    """

    def __init__(self, model=None, provider=None, **kwargs):
        super().__init__(name="StageRefinerAgent", model=model, provider=provider, **kwargs)

    def run(
        self,
        state: Dict[str, Any],
        stage: Dict[str, Any],
        error_output: str,
    ) -> Dict[str, Any]:
        """Refine a failing stage."""
        console.print(Panel(
            f"Refining Stage {stage['stage_index']+1}: {stage['stage_id']} (attempt {stage.get('refinement_attempts', 0)+1})",
            style="bold orange1"
        ))
        self.clear_history()

        # Build messages (include I/O helper code for refiner too)
        from Templates.prompt import _generate_io_helper_code
        io_helper_code = _generate_io_helper_code(state)

        system_content = STAGE_REFINE_SYSTEM.render(stage=stage)
        user_content = STAGE_REFINE_USER.render(
            stage=stage,
            error_output=error_output,
            analysis_document=build_analysis_document(state),
            io_helper_code=io_helper_code,
        )

        self.set_system_prompt(system_content)
        self.add_user_message(user_content)

        # Inject KB context
        kb_context = ExploitAgent()._build_kb_context(state)
        if kb_context:
            self.add_user_message(kb_context)

        console.print("[cyan]Calling LLM for stage refinement...[/cyan]")
        response_text = self.call_llm()
        parsed = parse_json_response(response_text)

        fixed_code = parsed.get("exploit_code", "")
        if not fixed_code and ("from pwn import" in response_text or "from pwnlib" in response_text):
            fixed_code = ExploitAgent()._extract_code_from_raw(response_text)

        if fixed_code:
            stage["code"] = fixed_code

            if parsed.get("changes_made"):
                console.print("[cyan]Changes Made:[/cyan]")
                for change in parsed["changes_made"]:
                    console.print(f"  • {change}")

            # Save
            binary_path = state.get("binary_path", "")
            if binary_path:
                exploit_path = Path(binary_path).resolve().parent / "exploit.py"
                exploit_path.write_text(fixed_code, encoding="utf-8")
                state["exploit_path"] = str(exploit_path)

            console.print("[green]Stage refined[/green]")
        else:
            console.print("[red]Failed to generate refined code[/red]")

        # Update stage in state
        staged = state.get("staged_exploit", {})
        stages = staged.get("stages", [])
        idx = stage.get("stage_index", 0)
        if idx < len(stages):
            stages[idx] = stage
            state["staged_exploit"]["stages"] = stages

        return state
