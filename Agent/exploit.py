"""
Exploit Agent - Generates pwntools exploit code.

Responsibilities:
- Generate working pwntools exploit code
- Use all gathered analysis information
- Handle edge cases and protections
"""

import time
from pathlib import Path
from typing import Any, Dict, List, Optional

from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax

from Agent.base import BaseAgent, parse_json_response

console = Console()


class ExploitAgent(BaseAgent):
    """
    Exploit Agent for PWN Solver.
    
    - Generate pwntools exploit code
    - Use all gathered analysis information
    """
    
    def __init__(
        self,
        model: Optional[str] = None,
        provider: Optional[str] = None,
        **kwargs
    ):
        super().__init__(name="ExploitAgent", model=model, provider=provider, **kwargs)
    
    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Run Exploit Agent."""
        console.print(Panel("Exploit Agent", style="bold red"))
        
        from Templates.prompt import build_messages
        
        # Build messages with full analysis
        messages = build_messages(
            agent="exploit",
            state=state,
            include_initial=False,
        )
        
        # Set system prompt and add user message
        if messages:
            self.set_system_prompt(messages[0]["content"])
            for msg in messages[1:]:
                if msg["role"] == "user":
                    self.add_user_message(msg["content"])
        
        console.print("[cyan]Calling LLM for exploit generation...[/cyan]")
        response_text = self.call_llm()
        
        # Parse response
        parsed = parse_json_response(response_text)
        
        state["exploit_output"] = {
            "agent": "exploit",
            "text": response_text,
            "json": parsed,
            "created_at": time.time(),
        }
        
        # Extract and display exploit code
        exploit_code = parsed.get("exploit_code", "")
        exploit_type = parsed.get("exploit_type", "unknown")
        
        if exploit_code:
            console.print(f"[green]Exploit Type: {exploit_type}[/green]")
            console.print(Panel(
                Syntax(exploit_code, "python", theme="monokai", line_numbers=True),
                title="Generated Exploit",
                border_style="red"
            ))

            # Save exploit to Challenge directory
            exploit_path = self._save_exploit(state, exploit_code)
            if exploit_path:
                state["exploit_path"] = str(exploit_path)
        
        # Show key steps
        key_steps = parsed.get("key_steps", [])
        if key_steps:
            console.print("[cyan]Key Steps:[/cyan]")
            for step in key_steps:
                console.print(f"  {step}")
        
        # Show assumptions
        assumptions = parsed.get("assumptions", [])
        if assumptions:
            console.print("[yellow]Assumptions:[/yellow]")
            for assumption in assumptions:
                console.print(f"  • {assumption}")
        
        return state
    
    def _save_exploit(self, state: Dict[str, Any], exploit_code: str) -> Optional[Path]:
        """Save exploit to Challenge directory."""
        binary_path = state.get("binary_path", "")
        if not binary_path:
            return None
        
        # Get challenge directory
        project_root = Path(__file__).resolve().parents[1]
        challenge_root = project_root / "Challenge"
        
        # Slugify binary name
        name = Path(binary_path).stem or "unknown"
        slug = "".join(
            c if c.isalnum() or c in "._-" else "_"
            for c in name.lower()
        ).strip("_") or "unknown"
        
        out_dir = challenge_root / slug
        out_dir.mkdir(parents=True, exist_ok=True)
        
        exploit_path = out_dir / "exploit.py"
        exploit_path.write_text(exploit_code, encoding="utf-8")
        
        console.print(f"[green]Exploit saved to: {exploit_path}[/green]")
        return exploit_path


# =============================================================================
# Exploit Refinement (for iterative improvement)
# =============================================================================

class ExploitRefinerAgent(BaseAgent):
    """
    Exploit Refiner Agent - Fixes failed exploits based on error output.
    
    This agent is used when the initial exploit fails verification.
    It analyzes the error and modifies the exploit code.
    """
    
    def __init__(
        self,
        model: Optional[str] = None,
        provider: Optional[str] = None,
        **kwargs
    ):
        super().__init__(name="ExploitRefinerAgent", model=model, provider=provider, **kwargs)
    
    def run(
        self,
        state: Dict[str, Any],
        error_output: str,
        current_exploit: str,
    ) -> Dict[str, Any]:
        """
        Refine exploit based on error.
        
        Args:
            state: Current solver state
            error_output: Error message from failed execution
            current_exploit: Current exploit code that failed
        """
        console.print(Panel("Exploit Refiner", style="bold orange1"))
        
        # Build refinement prompt
        system_prompt = """You are an expert at debugging pwntools exploits.

Given a failed exploit and its error output, fix the code to work correctly.

Output Format (STRICT JSON):
```json
{
  "reasoning": "Analysis of what went wrong and how to fix it",
  "exploit_code": "from pwn import *\\n\\n# Fixed exploit code...",
  "changes_made": ["List of changes made to fix the exploit"]
}
```

Focus on:
- Stack alignment issues (ret gadget)
- Incorrect offsets
- Wrong addresses
- Missing null byte handling
- Timing issues
"""
        
        user_prompt = f"""## Current Exploit (FAILED)

```python
{current_exploit}
```

## Error Output

```
{error_output}
```

## Analysis Document

Binary: {state.get("binary_path", "")}
Protections: {state.get("analysis", {}).get("checksec", {}).get("result", "Unknown")}

Please analyze the error and provide a fixed exploit.
"""
        
        self.set_system_prompt(system_prompt)
        self.add_user_message(user_prompt)
        
        console.print("[cyan]Calling LLM for exploit refinement...[/cyan]")
        response_text = self.call_llm()
        
        # Parse response
        parsed = parse_json_response(response_text)
        
        # Get fixed exploit
        fixed_exploit = parsed.get("exploit_code", "")
        
        if fixed_exploit:
            console.print("[green]Exploit refined[/green]")
            
            if "changes_made" in parsed:
                console.print("[cyan]Changes Made:[/cyan]")
                for change in parsed["changes_made"]:
                    console.print(f"  • {change}")
            
            # Update state with new exploit
            state["exploit_output"] = {
                "agent": "exploit_refiner",
                "text": response_text,
                "json": parsed,
                "created_at": time.time(),
            }
            
            # Save refined exploit
            ExploitAgent()._save_exploit(state, fixed_exploit)
        
        return state
