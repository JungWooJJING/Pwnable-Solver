"""
Exploit Agent - Generates pwntools exploit code.

Responsibilities:
- Generate working pwntools exploit code
- Use all gathered analysis information
- Handle edge cases and protections
"""

import time
from pathlib import Path
from typing import Any, Dict, List, Optional

from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax

from Agent.base import BaseAgent, parse_json_response, is_response_truncated, validate_python_code
from Templates.prompt import (
    build_messages, build_stage_exploit_messages, build_analysis_document,
    STAGE_IDENTIFY_SYSTEM, STAGE_IDENTIFY_USER,
    STAGE_REFINE_SYSTEM, STAGE_REFINE_USER,
)
from Store.knowledge import get_checksec_guide, get_heap_techniques, get_technique_guide, get_heap_constraint_guide

console = Console()

MAX_CODE_RETRIES = 1  # 응답 truncation 시 최대 재시도 횟수


def _ensure_valid_code(
    agent: BaseAgent,
    code: str,
    response_text: str,
    stage_hint: str = "",
) -> tuple:
    """
    Python 코드 문법 검증 후 truncation이 감지되면 LLM에 재시도 요청.

    Args:
        agent: 재시도 LLM 호출에 사용할 Agent (history가 이미 설정된 상태)
        code: 검증할 Python 코드
        response_text: 원본 LLM 응답 (truncation 감지용)
        stage_hint: 재시도 프롬프트에 포함할 컨텍스트 설명

    Returns:
        (final_code: str, is_valid: bool, error_msg: str)
    """
    is_valid, err = validate_python_code(code)
    if is_valid:
        return code, True, ""

    console.print(f"[yellow]⚠ Code syntax validation failed: {err}[/yellow]")

    truncated = is_response_truncated(response_text)
    if truncated:
        console.print("[yellow]Response appears truncated — retrying for complete code...[/yellow]")
    else:
        console.print("[red]Response not truncated but code has syntax error[/red]")

    retry_msg = (
        "Your previous response produced Python code with a syntax error and may have been cut off.\n"
        f"Error: {err}\n\n"
        "Please provide the COMPLETE exploit code again, starting from 'from pwn import *' "
        "through the final line. Do not truncate or omit any part."
    )
    if stage_hint:
        retry_msg += f"\nStage context: {stage_hint}"

    agent.add_user_message(retry_msg)

    try:
        retry_response = agent.call_llm()
    except Exception as e:
        console.print(f"[red]Retry LLM call failed: {e}[/red]")
        return code, False, err

    # Parse retry response
    retry_parsed = parse_json_response(retry_response)
    retry_code = retry_parsed.get("exploit_code", "")

    # Fallback: extract from raw response
    if not retry_code and ("from pwn import" in retry_response or "from pwnlib" in retry_response):
        # Inline extraction (avoid circular dependency on ExploitAgent._extract_code_from_raw)
        import re as _re
        m = _re.search(r'```python\s*(.*?)```', retry_response, _re.DOTALL)
        if m and ("from pwn import" in m.group(1) or "from pwnlib" in m.group(1)):
            retry_code = m.group(1).strip()
        if not retry_code:
            m = _re.search(r'(from pwn import \*.*?)(?:```|\n\n\n|$)', retry_response, _re.DOTALL)
            if m:
                retry_code = m.group(1).strip()

    if not retry_code:
        console.print("[red]Retry produced no code[/red]")
        return code, False, err

    retry_valid, retry_err = validate_python_code(retry_code)
    if retry_valid:
        console.print("[green]Retry produced valid code[/green]")
        return retry_code, True, ""
    else:
        console.print(f"[red]Retry code still invalid: {retry_err}[/red]")
        return retry_code, False, retry_err


class ExploitAgent(BaseAgent):
    """
    Exploit Agent for PWN Solver.
    
    - Generate pwntools exploit code
    - Use all gathered analysis information
    """
    
    def __init__(
        self,
        model: Optional[str] = None,
        provider: Optional[str] = None,
        **kwargs
    ):
        super().__init__(name="ExploitAgent", model=model, provider=provider, **kwargs)
    
    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Run Exploit Agent."""
        console.print(Panel("Exploit Agent", style="bold red"))

        self.clear_history()

        # Build messages with full analysis
        messages = build_messages(
            agent="exploit",
            state=state,
            include_initial=False,
        )

        # Set system prompt and add user message
        if messages:
            self.set_system_prompt(messages[0]["content"])
            for msg in messages[1:]:
                if msg["role"] == "user":
                    self.add_user_message(msg["content"])

        # Inject Knowledge Base techniques into context
        kb_context = self._build_kb_context(state)
        if kb_context:
            self.add_user_message(kb_context)
        
        console.print("[cyan]Calling LLM for exploit generation...[/cyan]")
        response_text = self.call_llm()
        
        # Parse response
        parsed = parse_json_response(response_text)

        state["exploit_output"] = {
            "agent": "exploit",
            "text": response_text,
            "json": parsed,
            "created_at": time.time(),
        }

        # Extract and display exploit code
        exploit_code = parsed.get("exploit_code", "")
        exploit_type = parsed.get("exploit_type", "unknown")

        # Fallback: Try to extract code from raw response if JSON parsing failed
        if not exploit_code and ("from pwn import" in response_text or "from pwnlib" in response_text):
            exploit_code = self._extract_code_from_raw(response_text)
            if exploit_code:
                console.print("[yellow]Extracted exploit code from raw response (JSON parse failed)[/yellow]")

        # Validate syntax and retry once if truncated
        if exploit_code:
            exploit_code, code_valid, code_err = _ensure_valid_code(
                self, exploit_code, response_text,
                stage_hint="ExploitAgent: full exploit generation",
            )
            if not code_valid:
                console.print(f"[yellow]Saving code despite syntax error: {code_err}[/yellow]")

        if exploit_code:
            console.print(f"[green]Exploit Type: {exploit_type}[/green]")
            console.print(Panel(
                Syntax(exploit_code, "python", theme="monokai", line_numbers=True),
                title="Generated Exploit",
                border_style="red"
            ))

            # Save exploit to Challenge directory
            exploit_path = self._save_exploit(state, exploit_code)
            if exploit_path:
                state["exploit_path"] = str(exploit_path)
        
        # Show key steps
        key_steps = parsed.get("key_steps", [])
        if key_steps:
            console.print("[cyan]Key Steps:[/cyan]")
            for step in key_steps:
                console.print(f"  {step}")
        
        # Show assumptions
        assumptions = parsed.get("assumptions", [])
        if assumptions:
            console.print("[yellow]Assumptions:[/yellow]")
            for assumption in assumptions:
                console.print(f"  • {assumption}")
        
        return state
    
    def _build_kb_context(self, state: dict) -> str:
        """Build Knowledge Base context for exploit generation."""
        analysis = state.get("analysis", {})
        checksec = analysis.get("checksec", {})
        vulns = analysis.get("vulnerabilities", [])
        libc = analysis.get("libc", {})
        sections = []

        # 1. Checksec-based strategy recommendation
        if checksec.get("done"):
            guide = get_checksec_guide(checksec)
            if guide.get("recommended"):
                sections.append("## Recommended Exploitation Techniques (from Knowledge Base)")
                for tech in guide["recommended"]:
                    sections.append(f"\n### {tech.get('name', '')}")
                    sections.append(f"**Strategy:** {tech.get('strategy', '')}")
                    if tech.get("steps"):
                        sections.append("**Steps:**")
                        for step in tech["steps"]:
                            sections.append(f"  {step}")
                    if tech.get("modern_template"):
                        sections.append(f"**Code Template:**\n```python\n{tech['modern_template'].strip()}\n```")

        # 2. Heap technique templates if heap vuln detected
        vuln_types = [v.get("type", "").lower() for v in vulns]
        is_heap = any(t in ("use_after_free", "heap_overflow", "double_free", "heap", "uaf") for t in vuln_types)
        if is_heap:
            glibc_ver = libc.get("version", "2.35")
            heap_techs = get_heap_techniques(str(glibc_ver))
            if heap_techs:
                sections.append("\n## Applicable Heap Techniques (glibc version-specific)")
                for tech in heap_techs:
                    sections.append(f"\n### {tech.get('name', '')} ({tech.get('key', '')})")
                    sections.append(f"  {tech.get('description', '')}")
                    if tech.get("version_notes"):
                        sections.append(f"  **Version Note:** {tech['version_notes']}")
                    if tech.get("modern_template"):
                        sections.append(f"  **Template:**\n```python\n{tech['modern_template'].strip()}\n```")
                    if tech.get("steps"):
                        sections.append("  **Steps:**")
                        for step in tech["steps"]:
                            sections.append(f"    {step}")

        # 3. Heap constraint guide (pointer structure → leak/write strategy)
        if is_heap:
            pointer_type = analysis.get("heap_pointer_type", "unknown")
            has_uaf = any(t in ("use_after_free", "uaf") for t in vuln_types)
            has_print = bool(analysis.get("io_patterns"))  # has print/read feature
            pie = checksec.get("pie", False)
            glibc_ver_str = str(libc.get("version", "2.35"))

            constraint_guide = get_heap_constraint_guide(
                pointer_type=pointer_type,
                has_uaf=has_uaf,
                has_print=has_print,
                pie=pie,
                glibc_version=glibc_ver_str,
            )

            sections.append("\n## Heap Exploit Strategy (Constraint-based)")
            sections.append(f"**Pointer type:** {constraint_guide['pointer_type']}")
            sections.append(f"**Recommended leak:** {constraint_guide['recommended_leak']}")
            sections.append(f"**Recommended write target:** {constraint_guide['recommended_write_target']}")
            if constraint_guide.get("warnings"):
                sections.append("**WARNINGS:**")
                for w in constraint_guide["warnings"]:
                    sections.append(f"  ⚠ {w}")
            if constraint_guide.get("recommended_flow"):
                sections.append("**Recommended exploit flow:**")
                for step in constraint_guide["recommended_flow"]:
                    sections.append(f"  → {step}")

        # 4. Strategy-specific technique guide
        strategy = analysis.get("strategy", "")
        if strategy:
            tech_guide = get_technique_guide(strategy)
            if tech_guide and tech_guide.get("modern_template"):
                sections.append(f"\n## Strategy-Specific Template: {tech_guide.get('name', strategy)}")
                sections.append(f"```python\n{tech_guide['modern_template'].strip()}\n```")

        return "\n".join(sections) if sections else ""

    def _extract_code_from_raw(self, text: str) -> str:
        """
        Extract Python exploit code from raw LLM response when JSON parsing fails.

        Looks for code blocks or 'from pwn import' patterns.
        """
        import re

        # Try to find code in ```python``` block
        python_match = re.search(r'```python\s*(.*?)```', text, re.DOTALL)
        if python_match:
            code = python_match.group(1).strip()
            if 'from pwn import' in code or 'from pwnlib' in code:
                return code

        # Try to find code in generic ``` block
        code_match = re.search(r'```\s*(from pwn.*?)```', text, re.DOTALL)
        if code_match:
            return code_match.group(1).strip()

        # Try to extract from "exploit_code": "..." in malformed JSON
        # Handle escaped newlines
        code_match = re.search(r'"exploit_code"\s*:\s*"((?:[^"\\]|\\.)*)', text, re.DOTALL)
        if code_match:
            code = code_match.group(1)
            # Unescape
            code = code.replace('\\n', '\n').replace('\\t', '\t').replace('\\"', '"').replace('\\\\', '\\')
            if 'from pwn import' in code or 'from pwnlib' in code:
                return code

        # Last resort: find 'from pwn import' and take everything until end or next section
        pwn_match = re.search(r'(from pwn import \*.*?)(?:```|\n\n\n|"reasoning"|$)', text, re.DOTALL)
        if pwn_match:
            return pwn_match.group(1).strip()

        return ""

    def _save_exploit(self, state: Dict[str, Any], exploit_code: str) -> Optional[Path]:
        """Save exploit to Challenge directory."""
        binary_path = state.get("binary_path", "")
        if not binary_path:
            return None
        
        # Save to same directory as the binary
        binary_dir = Path(binary_path).resolve().parent
        exploit_path = binary_dir / "exploit.py"
        exploit_path.write_text(exploit_code, encoding="utf-8")
        
        console.print(f"[green]Exploit saved to: {exploit_path}[/green]")
        return exploit_path


# =============================================================================
# Exploit Refinement (for iterative improvement)
# =============================================================================

class ExploitRefinerAgent(BaseAgent):
    """
    Exploit Refiner Agent - Fixes failed exploits based on error output.
    
    This agent is used when the initial exploit fails verification.
    It analyzes the error and modifies the exploit code.
    """
    
    def __init__(
        self,
        model: Optional[str] = None,
        provider: Optional[str] = None,
        **kwargs
    ):
        super().__init__(name="ExploitRefinerAgent", model=model, provider=provider, **kwargs)
    
    def run(
        self,
        state: Dict[str, Any],
        error_output: str,
        current_exploit: str,
    ) -> Dict[str, Any]:
        """
        Refine exploit based on error.
        
        Args:
            state: Current solver state
            error_output: Error message from failed execution
            current_exploit: Current exploit code that failed
        """
        console.print(Panel("Exploit Refiner", style="bold orange1"))
        
        # Build refinement prompt
        system_prompt = """You are an expert at debugging pwntools exploits.

Given a failed exploit and its error output, fix the code to work correctly.

Output Format (STRICT JSON):
```json
{
  "reasoning": "Analysis of what went wrong and how to fix it",
  "exploit_code": "from pwn import *\\n\\n# Fixed exploit code...",
  "changes_made": ["List of changes made to fix the exploit"]
}
```

Focus on:
- Stack alignment issues (ret gadget)
- Incorrect offsets
- Wrong addresses
- Missing null byte handling
- Timing issues

CRITICAL: NEVER use p.interactive(). After triggering shell, verify it:
```python
import time
time.sleep(0.5)
p.sendline(b'id')
time.sleep(0.5)
response = p.recvrepeat(timeout=2)
if b'uid=' in response:
    print('SHELL_VERIFIED')
    print(response.decode(errors='ignore'))
else:
    print('SHELL_FAILED')
    print(response.decode(errors='ignore'))
p.close()
```
"""
        
        # Build failure history context
        failure_history = state.get("exploit_failure_history", [])
        history_text = ""
        if len(failure_history) > 1:  # More than just the current failure
            history_text = "\n## Previous Failed Attempts (DO NOT REPEAT)\n"
            for f in failure_history[:-1]:  # Exclude current (already shown above)
                history_text += f"\n### Attempt {f.get('attempt', '?')}\n"
                history_text += f"Error: {f.get('error_summary', '')[:300]}\n"

        user_prompt = f"""## Current Exploit (FAILED)

```python
{current_exploit}
```

## Error Output

```
{error_output}
```

## Analysis Document

Binary: {state.get("binary_path", "")}
Protections: {state.get("analysis", {}).get("checksec", {}).get("result", "Unknown")}
{history_text}
Please analyze the error and provide a fixed exploit.
"""
        
        self.set_system_prompt(system_prompt)
        self.add_user_message(user_prompt)
        
        console.print("[cyan]Calling LLM for exploit refinement...[/cyan]")
        response_text = self.call_llm()
        
        # Parse response
        parsed = parse_json_response(response_text)

        # Get fixed exploit
        fixed_exploit = parsed.get("exploit_code", "")

        # Fallback: Try to extract code from raw response if JSON parsing failed
        if not fixed_exploit and ("from pwn import" in response_text or "from pwnlib" in response_text):
            fixed_exploit = ExploitAgent()._extract_code_from_raw(response_text)
            if fixed_exploit:
                console.print("[yellow]Extracted exploit code from raw response (JSON parse failed)[/yellow]")

        # Validate syntax and retry once if truncated
        if fixed_exploit:
            fixed_exploit, code_valid, code_err = _ensure_valid_code(
                self, fixed_exploit, response_text,
                stage_hint="ExploitRefinerAgent: fixing failed exploit",
            )
            if not code_valid:
                console.print(f"[yellow]Saving refined exploit despite syntax error: {code_err}[/yellow]")

        if fixed_exploit:
            console.print("[green]Exploit refined[/green]")
            
            if "changes_made" in parsed:
                console.print("[cyan]Changes Made:[/cyan]")
                for change in parsed["changes_made"]:
                    console.print(f"  • {change}")
            
            # Update state with new exploit
            state["exploit_output"] = {
                "agent": "exploit_refiner",
                "text": response_text,
                "json": parsed,
                "created_at": time.time(),
            }
            
            # Save refined exploit
            ExploitAgent()._save_exploit(state, fixed_exploit)

        return state


# =============================================================================
# Staged Exploit Agents (단계별 익스플로잇)
# =============================================================================

class StageIdentifierAgent(BaseAgent):
    """
    단계 식별 Agent - 분석 결과 기반으로 exploit 단계를 결정.

    출력: stages 리스트 [{stage_id, description, verification_marker}, ...]
    """

    def __init__(self, model=None, provider=None, **kwargs):
        super().__init__(name="StageIdentifierAgent", model=model, provider=provider, **kwargs)

    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Identify exploit stages from analysis."""
        console.print(Panel("Stage Identifier", style="bold magenta"))
        self.clear_history()

        analysis = state.get("analysis", {})

        # Build messages
        system_content = STAGE_IDENTIFY_SYSTEM.render()
        user_content = STAGE_IDENTIFY_USER.render(
            analysis_document=build_analysis_document(state),
            binary_path=state.get("binary_path", ""),
        )

        self.set_system_prompt(system_content)
        self.add_user_message(user_content)

        # Inject KB constraint guide (heap pointer type, leak strategy, etc.)
        kb_context = ExploitAgent()._build_kb_context(state)
        if kb_context:
            self.add_user_message(kb_context)

        # Inject deterministic stage hints
        kb_hint = self._build_stage_hint(analysis)
        if kb_hint:
            self.add_user_message(kb_hint)

        console.print("[cyan]Calling LLM for stage identification...[/cyan]")
        response_text = self.call_llm()
        parsed = parse_json_response(response_text)

        stages_raw = parsed.get("stages", [])
        if not stages_raw:
            # Fallback: single trigger stage
            console.print("[yellow]No stages identified, defaulting to single trigger stage[/yellow]")
            stages_raw = [{"stage_id": "trigger", "description": "Full exploit", "verification_marker": "SHELL_VERIFIED"}]

        # Build ExploitStage list
        stages = []
        for i, s in enumerate(stages_raw):
            stages.append({
                "stage_id": s.get("stage_id", f"stage{i+1}"),
                "stage_index": i,
                "description": s.get("description", ""),
                "code": "",
                "verified": False,
                "verification_marker": s.get("verification_marker", f"STAGE{i+1}_OK"),
                "output": "",
                "error": "",
                "refinement_attempts": 0,
            })

        # Ensure last stage marker is SHELL_VERIFIED
        if stages:
            stages[-1]["verification_marker"] = "SHELL_VERIFIED"

        state["staged_exploit"] = {
            "stages": stages,
            "current_stage_index": 0,
            "all_stages_verified": False,
        }

        # Display
        console.print(f"[green]Identified {len(stages)} stages:[/green]")
        for s in stages:
            console.print(f"  {s['stage_index']+1}. [{s['stage_id']}] {s['description']} → {s['verification_marker']}")

        if parsed.get("reasoning"):
            console.print(Panel(parsed["reasoning"], title="Reasoning", border_style="dim"))

        return state

    def _build_stage_hint(self, analysis: dict) -> str:
        """Build deterministic hints for stage identification."""
        checksec = analysis.get("checksec", {})
        vulns = analysis.get("vulnerabilities", [])
        result_str = str(checksec.get("result", "")).lower()

        hints = []

        # Protection hints
        nx = "nx enabled" in result_str
        pie = "pie" in result_str and "no pie" not in result_str
        canary = "canary found" in result_str and "no canary" not in result_str
        has_win = analysis.get("win_function", False)

        # Win function address hint (from known_symbols in analysis)
        win_addr = analysis.get("win_function_addr", "")

        vuln_types = [v.get("type", "").lower() for v in vulns]
        is_heap = any(t in ("use_after_free", "heap_overflow", "double_free", "uaf") for t in vuln_types)
        is_fmt = any(t in ("format_string",) for t in vuln_types)

        # =====================================================================
        # WIN FUNCTION: Takes priority over standard ret2libc flow
        # =====================================================================
        if has_win and not pie and not canary:
            addr_info = f" at {win_addr}" if win_addr else " (fixed address, no PIE)"
            hints.append(
                f"CRITICAL: Win function detected{addr_info} — NO PIE, NO CANARY → SINGLE STAGE.\n"
                "  - overflow directly → return to win function. NO libc leak needed. NO gadgets needed.\n"
                "  - Stage: trigger (1 stage only)"
            )
        elif has_win and not pie and canary:
            hints.append(
                "CRITICAL: Win function detected (no PIE) + CANARY → 2 STAGES.\n"
                "  - Stage 1: canary_leak — leak the canary value\n"
                "  - Stage 2: trigger — overflow with correct canary → ret to win (NO libc leak needed)\n"
                "  - Do NOT add a libc leak stage."
            )
        elif has_win and pie and not canary:
            hints.append(
                "CRITICAL: Win function detected + PIE (no canary) → 2 STAGES.\n"
                "  - Stage 1: pie_leak — leak binary base address (find a return address on stack)\n"
                "  - Stage 2: trigger — overflow → ret to pie_base + win_offset (NO libc leak needed)\n"
                "  - Do NOT add a libc leak stage."
            )
        elif has_win and pie and canary:
            hints.append(
                "CRITICAL: Win function detected + PIE + CANARY.\n"
                "\n"
                "⚠ KEY INSIGHT — saved RIP of main() is usually a LIBC address:\n"
                "  main() is called from __libc_start_call_main (a libc function), so the saved\n"
                "  return address at [rbp+8] is a libc pointer, NOT a binary (PIE) address.\n"
                "  → Do NOT compute pie_base from saved RIP. That gives libc base, not binary base.\n"
                "  → Use pwndbg (x/40gx $rsp, vmmap) to inspect the full stack and find which\n"
                "    addresses fall inside the binary's mapped range (use vmmap to identify it).\n"
                "  → PIE-range pointers often appear at stack positions past saved RIP\n"
                "    (e.g., the address of main() stored by the libc startup wrapper).\n"
                "\n"
                "STAGES: canary_pie_leak → trigger (2 stages total)\n"
                "\n"
                "  Stage 1 — canary_pie_leak:\n"
                "    Part A — canary leak:\n"
                "      Overflow just enough to overwrite canary's null byte (lowest byte).\n"
                "      puts()/printf(\"%s\",buf) will then print the remaining 7 canary bytes.\n"
                "      canary = b'\\x00' + recvn(7)  →  u64(canary_bytes)\n"
                "\n"
                "    Part B — PIE leak:\n"
                "      If puts() stops at null bytes in saved RBP before reaching saved RIP,\n"
                "      use a SECOND overflow that fills canary + saved_RBP + saved_RIP with\n"
                "      non-null bytes. This removes the null byte barrier so puts() continues\n"
                "      deeper into the stack, where a PIE-range pointer exists.\n"
                "      → Identify the exact stack offset using pwndbg dynamic verification.\n"
                "      → pie_base = leaked_binary_addr - <static offset from symbols>\n"
                "      → Validate: assert pie_base & 0xfff == 0\n"
                "\n"
                "    For LOOP-BASED programs (binary re-prompts for input in a loop):\n"
                "      Use separate loop iterations for canary round and PIE round.\n"
                "      After both leaks, plant the exploit payload in a third loop iteration\n"
                "      (within the normal max-length limit so the loop continues).\n"
                "      Then trigger program exit (e.g., sending a value beyond the limit)\n"
                "      so main() returns and executes the planted payload.\n"
                "      The loop exit MUST happen without overwriting the planted payload\n"
                "      (e.g., if the length check fires before memcpy, the stack is intact).\n"
                "\n"
                "  Stage 2 — trigger:\n"
                "    payload = b'A'*buf_offset + p64(canary) + b'A'*8 + p64(ret_gadget) + p64(win_addr)\n"
                "    ret_gadget: a bare 'ret' instruction for stack alignment before system() call.\n"
                "\n"
                "  Do NOT add a libc leak stage. Win function provides shell directly."
            )

        if canary:
            hints.append("HINT: Canary detected → canary must be leaked before any overflow.")

        # NX hint: only relevant when there's NO win function (otherwise win function is the target)
        if nx and not is_heap and not is_fmt and not has_win:
            hints.append("HINT: NX enabled, no win function → ret2libc: stages: leak (GOT leak) → trigger (system/one_gadget).")

        if is_heap:
            pointer_type = analysis.get("heap_pointer_type", "unknown")
            hints.append(f"HINT: Heap vulnerability detected (pointer type: {pointer_type}). "
                        "Likely stages: leak → write → trigger.")
            if pointer_type == "single":
                hints.append(
                    "CRITICAL: Single pointer program — unsorted bin leak WILL NOT WORK.\n"
                    "  - Only one chunk tracked at a time → no guard chunk → freed chunk merges with top.\n"
                    "  - You MUST use stdout BSS partial overwrite technique for the leak stage.\n"
                    "  - Stage description must mention 'stdout BSS partial overwrite', NOT 'unsorted bin'."
                )
            elif pointer_type == "array":
                hints.append(
                    "HINT: Array pointer program — unsorted bin leak works (can keep guard chunk)."
                )

        if is_fmt:
            hints.append("HINT: Format string detected → stages: leak (%p) → write (%n GOT overwrite) → trigger.")

        return "\n".join(hints) if hints else ""


class StageExploitAgent(BaseAgent):
    """
    단계별 Exploit 코드 생성 Agent.

    현재 단계에 대한 완전한 실행 가능 스크립트를 생성.
    이전 verified 단계의 코드를 포함.
    """

    def __init__(self, model=None, provider=None, **kwargs):
        super().__init__(name="StageExploitAgent", model=model, provider=provider, **kwargs)

    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Generate exploit code for current stage."""
        staged = state.get("staged_exploit", {})
        stages = staged.get("stages", [])
        current_idx = staged.get("current_stage_index", 0)

        if current_idx >= len(stages):
            console.print("[red]No more stages to generate[/red]")
            return state

        current_stage = stages[current_idx]
        console.print(Panel(
            f"Stage {current_idx+1}/{len(stages)}: {current_stage['stage_id']} — {current_stage['description']}",
            style="bold red"
        ))
        self.clear_history()

        # Collect verified stages' code
        verified_stages = []
        for s in stages[:current_idx]:
            if s.get("verified") and s.get("code"):
                verified_stages.append({
                    "stage_id": s["stage_id"],
                    "code": s["code"],
                    "output": s.get("output", "")[:500],
                })

        # Build messages
        messages = build_stage_exploit_messages(state, current_stage, verified_stages)

        self.set_system_prompt(messages[0]["content"])
        for msg in messages[1:]:
            if msg["role"] == "user":
                self.add_user_message(msg["content"])

        # Inject KB context
        kb_context = ExploitAgent()._build_kb_context(state)
        if kb_context:
            self.add_user_message(kb_context)

        console.print(f"[cyan]Calling LLM for Stage {current_idx+1} code generation...[/cyan]")
        response_text = self.call_llm()
        parsed = parse_json_response(response_text)

        exploit_code = parsed.get("exploit_code", "")
        if not exploit_code and ("from pwn import" in response_text or "from pwnlib" in response_text):
            exploit_code = ExploitAgent()._extract_code_from_raw(response_text)
            if exploit_code:
                console.print("[yellow]Extracted code from raw response[/yellow]")

        # Validate syntax and retry once if truncated
        if exploit_code:
            exploit_code, code_valid, code_err = _ensure_valid_code(
                self, exploit_code, response_text,
                stage_hint=f"Stage {current_idx+1} ({current_stage['stage_id']}): {current_stage['description']}",
            )
            if not code_valid:
                console.print(f"[yellow]Saving code despite syntax error: {code_err}[/yellow]")

        if exploit_code:
            current_stage["code"] = exploit_code

            console.print(Panel(
                Syntax(exploit_code, "python", theme="monokai", line_numbers=True),
                title=f"Stage {current_idx+1}: {current_stage['stage_id']}",
                border_style="red"
            ))

            # Save to file
            exploit_path = self._save_stage_exploit(state, exploit_code)
            if exploit_path:
                state["exploit_path"] = str(exploit_path)

            # Show key steps
            for step in parsed.get("key_steps", []):
                console.print(f"  {step}")
        else:
            console.print("[red]Failed to generate exploit code for this stage[/red]")

        stages[current_idx] = current_stage
        state["staged_exploit"]["stages"] = stages

        return state

    def _save_stage_exploit(self, state: Dict[str, Any], code: str) -> Optional[Path]:
        """Save stage exploit to Challenge directory (both exploit.py and per-stage file)."""
        binary_path = state.get("binary_path", "")
        if not binary_path:
            return None

        binary_dir = Path(binary_path).resolve().parent

        # Save current stage code to exploit.py (latest)
        exploit_path = binary_dir / "exploit.py"
        exploit_path.write_text(code, encoding="utf-8")

        # Also save per-stage file so previous stages aren't overwritten
        staged = state.get("staged_exploit", {})
        stages = staged.get("stages", [])
        current_idx = staged.get("current_stage_index", 0)
        if current_idx < len(stages):
            stage_id = stages[current_idx].get("stage_id", f"stage{current_idx+1}")
            stage_file = binary_dir / f"exploit_stage{current_idx+1}_{stage_id}.py"
            stage_file.write_text(code, encoding="utf-8")
            console.print(f"[green]Stage exploit saved to: {stage_file}[/green]")

        return exploit_path


class StageRefinerAgent(BaseAgent):
    """
    단계별 Exploit 수정 Agent.

    실패한 단계의 코드만 수정. 이전 verified 단계는 건드리지 않음.
    """

    def __init__(self, model=None, provider=None, **kwargs):
        super().__init__(name="StageRefinerAgent", model=model, provider=provider, **kwargs)

    def run(
        self,
        state: Dict[str, Any],
        stage: Dict[str, Any],
        error_output: str,
    ) -> Dict[str, Any]:
        """Refine a failing stage."""
        console.print(Panel(
            f"Refining Stage {stage['stage_index']+1}: {stage['stage_id']} (attempt {stage.get('refinement_attempts', 0)+1})",
            style="bold orange1"
        ))
        self.clear_history()

        # Build messages (include I/O helper code for refiner too)
        from Templates.prompt import _generate_io_helper_code
        io_helper_code = _generate_io_helper_code(state)

        # Try to extract C source code from the binary directory for the refiner
        source_code_snippet = ""
        try:
            import glob as _glob, os as _os
            binary_path = state.get("binary_path", "")
            if binary_path:
                workdir = _os.path.dirname(_os.path.abspath(binary_path))
                for c_file in _glob.glob(_os.path.join(workdir, "*.c")):
                    with open(c_file, "r", errors="replace") as _f:
                        source_code_snippet += f"// Source: {_os.path.basename(c_file)}\n"
                        source_code_snippet += _f.read()[:4000]
                        break  # only first .c file
        except Exception:
            pass

        # Also try to extract from runs history (cat *.c commands)
        if not source_code_snippet:
            for run in state.get("runs", []):
                cmd_str = " ".join(str(c) for c in run.get("commands", []))
                if ".c" in cmd_str and "cat" in cmd_str:
                    stdout = run.get("stdout", "")
                    if stdout and "#include" in stdout:
                        source_code_snippet = stdout[:4000]
                        break

        system_content = STAGE_REFINE_SYSTEM.render(
            stage=stage,
            docker_port=state.get("docker_port", 0),
        )
        user_content = STAGE_REFINE_USER.render(
            stage=stage,
            error_output=error_output,
            analysis_document=build_analysis_document(state),
            io_helper_code=io_helper_code,
            source_code_snippet=source_code_snippet,
        )

        self.set_system_prompt(system_content)
        self.add_user_message(user_content)

        # Inject KB context
        kb_context = ExploitAgent()._build_kb_context(state)
        if kb_context:
            self.add_user_message(kb_context)

        console.print("[cyan]Calling LLM for stage refinement...[/cyan]")
        response_text = self.call_llm()
        parsed = parse_json_response(response_text)

        fixed_code = parsed.get("exploit_code", "")
        if not fixed_code and ("from pwn import" in response_text or "from pwnlib" in response_text):
            fixed_code = ExploitAgent()._extract_code_from_raw(response_text)

        # Validate syntax and retry once if truncated
        if fixed_code:
            fixed_code, code_valid, code_err = _ensure_valid_code(
                self, fixed_code, response_text,
                stage_hint=f"StageRefiner attempt {stage.get('refinement_attempts', 0)} "
                           f"for stage '{stage.get('stage_id', '?')}'",
            )
            if not code_valid:
                console.print(f"[yellow]Saving refined code despite syntax error: {code_err}[/yellow]")

        if fixed_code:
            stage["code"] = fixed_code

            if parsed.get("changes_made"):
                console.print("[cyan]Changes Made:[/cyan]")
                for change in parsed["changes_made"]:
                    console.print(f"  • {change}")

            # Save (both exploit.py and per-stage file)
            binary_path = state.get("binary_path", "")
            if binary_path:
                binary_dir = Path(binary_path).resolve().parent
                exploit_path = binary_dir / "exploit.py"
                exploit_path.write_text(fixed_code, encoding="utf-8")
                state["exploit_path"] = str(exploit_path)

                stage_idx = stage.get("stage_index", 0)
                stage_id = stage.get("stage_id", f"stage{stage_idx+1}")
                stage_file = binary_dir / f"exploit_stage{stage_idx+1}_{stage_id}.py"
                stage_file.write_text(fixed_code, encoding="utf-8")
                console.print(f"[green]Refined stage saved to: {stage_file}[/green]")

            console.print("[green]Stage refined[/green]")
        else:
            console.print("[red]Failed to generate refined code[/red]")

        # Update stage in state
        staged = state.get("staged_exploit", {})
        stages = staged.get("stages", [])
        idx = stage.get("stage_index", 0)
        if idx < len(stages):
            stages[idx] = stage
            state["staged_exploit"]["stages"] = stages

        return state
